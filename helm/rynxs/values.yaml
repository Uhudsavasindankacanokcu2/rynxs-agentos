# Image configuration
image:
  repository: ghcr.io/rynxs/operator
  tag: v0.1.0
  pullPolicy: IfNotPresent

# Replica count (for HA with leader election)
replicaCount: 1

# PodDisruptionBudget (E3 post-review)
# Ensures minimum availability during voluntary disruptions (node drains, rolling updates)
podDisruptionBudget:
  enabled: true
  minAvailable: 1  # At least 1 pod must be available during disruptions
  # maxUnavailable: 1  # Alternative: max 1 pod can be unavailable

# Pod scheduling (E3 production hardening)
# RECOMMENDED: Use topologySpreadConstraints for multi-zone HA
# Spreads pods across nodes AND zones with deterministic maxSkew control
topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname  # Spread across nodes
    whenUnsatisfiable: ScheduleAnyway  # Soft constraint (prefer, don't require)
    labelSelector:
      matchLabels:
        app.kubernetes.io/name: rynxs
  - maxSkew: 1
    topologyKey: topology.kubernetes.io/zone  # Spread across zones
    whenUnsatisfiable: ScheduleAnyway  # Soft constraint
    labelSelector:
      matchLabels:
        app.kubernetes.io/name: rynxs

# Alternative: podAntiAffinity (less flexible, use if cluster doesn't support topologySpreadConstraints)
# Uncomment to use instead of topologySpreadConstraints
# affinity:
#   podAntiAffinity:
#     preferredDuringSchedulingIgnoredDuringExecution:
#       - weight: 100
#         podAffinityTerm:
#           labelSelector:
#             matchLabels:
#               app.kubernetes.io/name: rynxs
#           topologyKey: kubernetes.io/hostname

# Resources
resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 100m
    memory: 128Mi

# RBAC
rbac:
  create: true
  serviceAccountName: rynxs-operator

# CRDs
crds:
  create: true

# Persistence (operator event log)
persistence:
  enabled: true
  size: 10Gi
  storageClass: ""  # Use cluster default
  accessMode: ReadWriteOnce
  # Keep PVC on helm uninstall (prevents event log deletion)
  # WARNING: If true, PVC will become orphaned and may cause name collision on reinstall
  keepOnUninstall: false

# Leader Election (E3)
leaderElection:
  enabled: false
  leaseDurationSeconds: 30  # How long non-leader will wait to takeover
  renewDeadlineSeconds: 20  # Leader must renew within this window
  retryPeriodSeconds: 5     # Check interval for leadership

# Log Sink (E2)
logSink:
  type: file  # Options: file, s3
  s3:
    enabled: false
    endpoint: ""
    bucket: ""
    region: us-east-1
    accessKeySecret: ""  # Name of k8s secret with AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY

# MinIO (E2.4) - Optional S3-compatible object storage
# Deploy MinIO alongside operator for S3 event log storage
minio:
  enabled: false
  image:
    repository: minio/minio
    tag: RELEASE.2024-11-07T00-15-16Z  # Pin to specific version for supply chain security
    pullPolicy: IfNotPresent

  # MinIO credentials
  # RECOMMENDED: Use existingSecret for production
  # If existingSecret is set, rootUser/rootPassword are ignored
  existingSecret: ""  # Name of existing secret with MINIO_ROOT_USER and MINIO_ROOT_PASSWORD keys
  rootUser: minioadmin  # Only used if existingSecret is empty (dev/test only)
  rootPassword: minioadmin  # Only used if existingSecret is empty (dev/test only)

  # Storage
  persistence:
    enabled: true
    size: 5Gi
    storageClass: ""  # Use cluster default
    accessMode: ReadWriteOnce

  # Resources
  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 2Gi

  # Service
  service:
    type: ClusterIP
    port: 9000

# Observability (E4)
metrics:
  enabled: false
  port: 8080
  path: /metrics
  annotations: {}
    # prometheus.io/scrape: "true"
    # prometheus.io/port: "8080"
    # prometheus.io/path: "/metrics"

  # ServiceMonitor for Prometheus Operator
  # (https://github.com/prometheus-operator/prometheus-operator)
  serviceMonitor:
    enabled: false
    interval: 30s
    scrapeTimeout: 10s
    labels: {}
    relabelings: []
    metricRelabelings: []

  # NetworkPolicy for metrics endpoint (E3 production hardening)
  # Restricts access to metrics endpoint (HTTP-only) to Prometheus pods
  networkPolicy:
    enabled: false  # Disabled by default, enable in production for security
    # Allow scraping from specific namespace (e.g., monitoring)
    # IMPORTANT: Use standard K8s 1.21+ label (not .name)
    prometheusNamespaceSelector: {}
      # kubernetes.io/metadata.name: monitoring
    # Allow scraping from specific pods (e.g., prometheus)
    prometheusPodSelector: {}
      # app.kubernetes.io/name: prometheus

# Logging
logging:
  level: INFO
  format: json

# Security (Pod-level)
securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000

# Probes (E1.2)
probes:
  liveness:
    enabled: true
    path: /healthz
    port: 8080
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 2
    failureThreshold: 6
  readiness:
    enabled: false
    path: /ready
    port: 8080
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 2
    failureThreshold: 3

# Extra env / args (optional but handy)
extraEnv: []
extraArgs: []

# Name overrides (optional)
nameOverride: ""
fullnameOverride: ""
